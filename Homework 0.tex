\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{fullpage}
\usepackage{setspace}

\title{CMPT 404\\Homework 0}
\author{Daniel Clark}
\date{\today}

\begin{document}
\maketitle

\begin{description} 
\begin{doublespace}


\item[1.] For the function $g(x) = -3x^2 + 24x - 30$, find the value for $x$ that maximizes $g(x)$.

In order to maximize the function, first we take to derivative of the function and get that $\frac{d} {dx} g(x) = g'(x) = -6x + 24$. Next, we set this equal to zero to find the critical points and find that  $x = 4$. This is a maximum with $g(4) = 18$.



\item[2.] Differentiate $f(x) = 3x_0^3 - 2 x_0 x_1^2 +4x_1 -8$ with respect to $x_0$ and $x_1$.
\[
	\frac{d}{dx_0} f(x) = 9x_0^2 - 2x_1^2
\]
\[
	\frac{d}{dx_1} f(x) = -4x_0 x_1 + 4
\]

\newpage


\item[3.] Consider the matrix $A =  \begin{bmatrix} 1 & 4 & -3 \\ 2 & -1 & 3\end{bmatrix}$ and $B =  \begin{bmatrix} -2 & 0 & 5 \\ 0 & -1 & 4\end{bmatrix}$.

\item[a)] Can you multiply the two matices?

	You cannot multiply these matrices as the dimentions are incompatible.

\item[b)] Multiply $A^T$ and $B$ and give its $rank$.
\[
	A^TB = \begin{bmatrix} -2 & -2 & 13 \\ -8 & 1 & 16 \\ 6 & -3 & -3 \end{bmatrix}
\]
This has a rank of 2.



\item[4.] Definitions
\\The Simple Gaussian Distribution is a symmetric, bell shaped probability curve.
\\The multivariate Gaussian Distribution is a multivariate analog to the Simple Gaussian Distribution in which each variable creates a Simple Gaussian Distribution when the other variables are held constant.
\\The Bernoulli Distribution is a distribution that gives 1 with a given probability, and 0 otherwise.
\\The Binomial Distribution describes the probability of a number of succeses in a series of Bernoulli trials.
\\The Exponential Distribution is a constantly decreasing probability curve given by a negative exponential function.



\item[6.] Take the random variable $X ~ N(2,3)$. What is its expected value?

	The expected value is the mean, which is 2.

\newpage


\item[7. a)] What is $x^*$ if $y = 1.1$ and $Z = \mathbb{N}$, where $\mathbb{N}$ is the set of natural numbers?

	Since 1 is the closest natural number to 1.1, $x^* = 1$.


\item[7. b)] Locate $x^*$ in the following picture:
\newpage


\item[8.] Suppose that random variable $Y$ has the following distribution:
\[
	p(y) =
	\left\{
		\begin{array}{ll}
			e^{-y}  & \mbox{if } y \geq 0 \\
			0 & \mbox{if } y < 0
		\end{array}
	\right.
\]

\item[a)] Verify that  $\int \limits_{-\infty} ^{\infty} p(y)dy = 1$.
\[
	\int \limits_{-\infty} ^{\infty} p(y)dy = \int \limits_0 ^{\infty} e^{-y}dy = -e^{-y} |_0^\infty = 0 - (-1) = 1
\]

\item[b)] What is $\mu_Y = E[Y] =  \int \limits_{-\infty} ^{\infty} p(y)y$?
\[
	\int \limits_{-\infty} ^{\infty} p(y)ydy = \int \limits_0 ^{\infty} e^{-y}dy = -e^{-y}y|_0^\infty + \int \limits_0 ^{\infty} e^{-y}dy = (0 - 0) + 1 = 1
\]

\item[c)] What is $\sigma_Y =$ Var$[Y] =  \int \limits_{-\infty} ^{\infty} p(y)(y - \mu_Y)^2dy$?
\begin{align*}
	\int \limits_{-\infty} ^{\infty} p(y)(y - \mu_Y)^2dy &= \int \limits_0 ^{\infty} e^{-y}(y - 1)^2dy \\
		&= -(y-1)^2e^{-y} |_0^\infty + 2 \int \limits_0 ^{\infty} e^{-y}(y - 1)dy \\
		&= 1 + 2 ( \int \limits_0 ^{\infty} e^{-y}dy - \int \limits_0 ^{\infty} e^{-y}dy) \\
		&= 1 + 2(1-1) = 1
\end{align*}

\item[d)] What is $E[Y| Y \geq 10]$?
\[
	E[Y|Y\geq10] = \frac {\int \limits_{10} ^{\infty} e^{-y}ydy} {\int \limits_{10} ^{\infty} e^{-y}dy} = \frac {-e^{-y}(y+1) |_{10}^\infty} {-e^{-y} |_{10}^\infty} = \frac{11 e^{-10}} {e^{-10}} = 11
\]



\end{doublespace}
\end{description}
\end{document}

